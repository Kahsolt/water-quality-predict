# water-quality-predict

    æ°´è´¨æ£€æµ‹æŒ‡æ ‡çš„æ—¶é—´åºåˆ—é¢„æµ‹å¹³å°åŽç«¯

----

ä½ å¦ˆçš„ðŸ˜ ï¼Œè¯´èµ·æ¥æ˜¯ä¸ªå¾ˆç®€å•çš„toyï¼Œä½†æ˜¯å·®ä¸å¤šå†™äº†ä¸€æ•´å¥—æ‰¹å¤„ç†ä½œä¸šæ¡†æž¶â€¦â€¦  
çŽ°åœ¨å˜æˆä¸€ä¸ªå¹³å°æ€§çš„ä½œä¸šæµäº†ï¼šæäº¤æ•°æ®é›†å¹¶åˆ›å»ºä»»åŠ¡ -> æ— è„‘è®­ç»ƒè‹¥å¹²ä¸ªé¢„æµ‹å™¨ -> ç”¨æ€§èƒ½æœ€å¥½çš„é¢„æµ‹å™¨åº”å¯¹æ–°çš„æŸ¥è¯¢  


### Web API

âšª Native API

- start server `python app.py`
- point your browser to `http://127.0.0.1:5000/` to see API documentation

Main busisness:

- `POST /task` to create a task and put in processing queue
- `GET /task/<name>` to get task results 
- `POST /task/<name>` to retrain a old task with new data
- `POST /infer` to predict on new data

Extras:

- `GET /runtime` to see running queue status and history
- `GET /job/<name>` or `POST /job/<name>` to prepare your job plans
- `GET /log/<task_name>` to download the task log folder
- `GET /log/<task_name>/<job_name>` to download the job log folder
- `GET /log/<task_name>/<job_name>.log` to see job log
- `POST /merge_csv` to merge data all-in-one if you have multiple data source

=> see client demo: [app_test.py](app_test.py)


### Local run

âšª Data

- prepare your `*.csv` files (suggested to put under `data` folder)
- each file can contain several columns
  - the first columns is datetime in ISO 8601 format, e.g. `2022-09-27 18:00:00.000`
  - the rest columns are float data from your sensor devices
    - the last column is to predict on

âšª Dataset & Train & Eval

- write a job file, see guide => [doc/job.md](doc/job.md)
- run a single job: `python run.py -D path/to/*.csv -J path/to/*.yaml --target all`
- run folder of jobs: `py run.py -D data\test.csv -X job`
  - run all test demo: `run_test.cmd`

âšª Infer

![demo](img/demo.png)

- run `python infer.py`


----
by Armit
2022/09/15  
2023/02/14  
